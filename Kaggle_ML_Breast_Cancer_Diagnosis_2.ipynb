{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1aaf1c",
   "metadata": {},
   "source": [
    "# Use of Machine Learning in Diagnosing Breast Cancer\n",
    "# [Part 2] Hyperparameter optimization using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e90f54",
   "metadata": {},
   "source": [
    "When your choosing a model for machine learning, it's never easy to know which model to choose as the best that can be used on your data without trying them. There are different methods that can be used to find what are the best hyperparameters that can be used in our work and of interest here we use the **GridSearch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1571db16",
   "metadata": {},
   "source": [
    "Hopefully it will improve on the performance as compared to the results in part1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489b29a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1ebb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01328de7",
   "metadata": {},
   "source": [
    "## Import the data from the previous part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0a4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Processed_breast_cancer_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9d3d7",
   "metadata": {},
   "source": [
    "### From part1, let's list down the features we obtained from the correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c017d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_var = ['radius_mean',\n",
    " 'perimeter_mean',\n",
    " 'area_mean',\n",
    " 'compactness_mean',\n",
    " 'concavity_mean',\n",
    " 'concave points_mean',\n",
    " 'radius_se',\n",
    " 'perimeter_se',\n",
    " 'area_se',\n",
    " 'concave points_se',\n",
    " 'radius_worst',\n",
    " 'perimeter_worst',\n",
    " 'area_worst',\n",
    " 'concavity_worst',\n",
    " 'concave points_worst',\n",
    " 'fractal_dimension_worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f571ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.15, random_state=1)\n",
    "#the random_state value of 1 sets seed to the random generator and this allows us to get the same value each time the algorithm runs\n",
    "\n",
    "train_X = train[prediction_var]\n",
    "train_y = train['diagnosis']\n",
    "test_X = test[prediction_var]\n",
    "test_y = test['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cadd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704aadbb",
   "metadata": {},
   "source": [
    "### Let's use the RandomForestClassifier as our model sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00fd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b1f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': (1,2,3,4), 'n_estimators': (10,50,100,500)}\n",
    "\n",
    "best_model = GridSearchCV(model, parameters)\n",
    "#best_model.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f36a675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': (1, 2, 3, 4),\n",
       "                         'n_estimators': (10, 50, 100, 500)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e668cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 100}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76aefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = best_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f963b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc1c3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  1],\n",
       "       [ 5, 29]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b26957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision score is 0.97\n",
      "The recall score is 0.85\n",
      "The accuracy score is 0.93\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_y, prediction)\n",
    "print('The precision score is %.2f' % precision)\n",
    "recall = recall_score(test_y, prediction)\n",
    "print('The recall score is %.2f' % recall)\n",
    "accuracy = accuracy_score(test_y, prediction)\n",
    "print('The accuracy score is %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cba23f",
   "metadata": {},
   "source": [
    "Comparing the results of the model with default parameters and our optimized model with manually set parameters, the scores are the same.\n",
    "It can be assumed that even with the default parameters, the algorithm has been set to produce the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1304166",
   "metadata": {},
   "source": [
    "`Note:`It is important to perform hyperparameter optimization to generate results that are dependent on the goal of the ML. It is important to know that sometimes there exists a trade off between the Precision_score and the Recall_score\n",
    "\n",
    "For example, for our dataset, we can consider that achieving a high recall is more important than getting a high precision â€“ we would like to detect as many cancers as possible. In a practical set-up within a hospital, we don't want to subject patients to surgeries and medications when there is a chance that its just a false positive. On the other hand, if the doctor deems that even the cases where patients who were diagnosed as false positives are possible indications of some other underlying condition, then the precision score becomes equally important and thus one would aim for a good F1-score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
